# ğŸ“š Enhanced Interactive Learning Assistant (Powered by Ollama LLM)

## ğŸ§© Overview

This project is a modular and extensible **Interactive Learning Assistant** powered by a local LLM (LLaMA3 via Ollama) and a FastAPI backend. It simulates personalized research, generates structured reports, and enables iterative improvement based on user feedback.

---

## âœ… Expected Deliverables

1. âœ… **Working Prototype**: Handles topic research, report generation, and feedback updates.
2. âœ… **Source Code**: Well-organized and documented in a Dockerized environment.
3. âœ… **Sample Topics & Reports**: Available in the `/samples` folder.
4. âœ… **README File**: (You are reading it) â€“ details setup, architecture, and methodology.
5. âœ… **Sample Input/Output**: Included below.

---

## ğŸ”§ Setup Instructions

> Requires: Docker, Ollama (installed and running locally), Python 3.9+

### 1. Install and Start Ollama
Install Ollama: https://ollama.com

Start the LLaMA3 model:
```bash
ollama run llama3
```

> âš ï¸ **Note**: Ensure your system has at least **6 GB** free RAM. If not, consider using a lighter model or a cloud-based LLM API.

### 2. Build and Run the Application
```bash
docker build -t learning-assistant .
docker run -p 8000:8000 learning-assistant
```

Access at: `http://localhost:8000/docs` (FastAPI Swagger UI)

---

## ğŸ§  System Architecture

```
Client (Browser or Tool)
       â”‚
       â–¼
+---------------------------+
|        FastAPI App        |
+---------------------------+
â”‚  â”œâ”€ /generate-report      â”‚
â”‚  â”œâ”€ /update-report        â”‚
â”‚  â””â”€ OllamaService         â”‚
â”‚           â”‚
â”‚           â–¼
â”‚     [LLaMA3 via Ollama]
â”‚
â””â”€ Templates (Jinja2)
       â””â”€ HTML Reports
```

- **Backend**: Python + FastAPI
- **LLM**: LLaMA3 via Ollama (local inference)
- **Templating**: Jinja2 for HTML reports
- **Dockerized**: 1-line setup for full system

---

## ğŸ” Research Methodology

Prompts are structured and dynamically created to simulate research from:

- ğŸŒ General web content
- ğŸ¥ Video transcripts (simulated)
- ğŸ“š Academic-style literature

This method enables **context-aware** content generation without live crawling.

---

## ğŸ¯ Personalization Approach

The system adapts responses based on:

- ğŸ’¡ User interest (technical, creative, academic)
- ğŸ“ˆ Skill level (beginner, intermediate, expert)
- ğŸ“˜ Preferred format (summary, full report, Q&A)

Interactive Q&A helps refine reports progressively.

---

## ğŸ“ Report Generation

- **Structured Output**: Sections build from fundamentals to advanced topics.
- **Enhanced Content**:
  - Diagrams & visual resource links
  - Summaries and explanations
  - References and follow-up suggestions
- **Templated Reports** using Jinja2

---

## ğŸ”„ Report Modification API

**Endpoint**: `/update-report`

Allows:
- Feedback-driven modifications
- Regeneration of specific sections
- Personalization tuning

---

## ğŸ“¥ Sample Input/Output

### ğŸ¯ Input Prompt:
```json
{
  "topic": "Quantum Computing for Beginners",
  "audience_level": "beginner",
  "format": "structured_report"
}
```

### ğŸ§¾ Output:
```html
<h1>Introduction to Quantum Computing</h1>
<p>Quantum computing leverages quantum bits, or qubits, which can exist in multiple states at once...</p>

<h2>Core Concepts</h2>
<ul>
  <li>Superposition</li>
  <li>Entanglement</li>
  <li>Quantum Gates</li>
</ul>

<h3>Visual Resources</h3>
<p><a href="https://example.com/quantum-visual">Quantum Concepts in Visuals</a></p>

<h3>Next Steps</h3>
<p>To dive deeper, explore Qiskit by IBM...</p>
```

ğŸ§ª Sample reports can be found in `/samples/reports/`

---

## ğŸš« Limitations

- âŒ Ollama LLM must be running locally â€“ high memory usage (~6 GB).
- âŒ No live data fetching â€“ all research is simulated.
- âŒ UI not implemented â€“ currently backend API only.

---

## ğŸš€ Future Improvements

- ğŸ” Persistent user sessions with history
- ğŸ“„ PDF export and bookmarking
- ğŸ“š Vector store for user memory/contextual follow-up
- ğŸŒ Optional cloud LLM fallback (for low-RAM systems)
- ğŸ›ï¸ Web-based frontend UI

---

## ğŸ“‚ Submission Checklist

- [x] **Code Repository**: Organized and modular
- [x] **Docker Setup**: Single command deployment
- [x] **README**: Full setup and architectural guide
- [x] **Sample Reports**: Provided for evaluation
- [x] **Demo Media**: Screenshots or screen recording included
- [x] **Focus on Core Features**: Prioritized functionality

---

## ğŸ§  Technology Justification

- **FastAPI**: Lightweight, async-ready API framework
- **Ollama**: Offline-friendly LLM platform
- **Docker**: Clean, portable deployment
- **Jinja2**: Flexible templating for content formatting

---

## ğŸ“¸ Demo Screenshots

> _Include screenshots of `/docs`, `/generate-report`, and sample HTML report preview._

---

## ğŸ™Œ Author

**Anil** â€“ Final year B.Tech (AI/ML), SRM University, AP  
Passionate about AI, software engineering, and building meaningful tools with LLMs.

---
